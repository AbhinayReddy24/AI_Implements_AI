{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "os.environ[\"TOKENIZERS_PARALLEMISM\"] = \"False\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import SimpleDirectoryReader\n",
    "documents = SimpleDirectoryReader(input_files=[\"/Users/abhinay/Desktop/Real-Time_Detection_of_DNS_Exfiltration_and_Tunneling_from_Enterprise_Networks-1.pdf\"]\n",
    "                                  ).load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> \n",
      "\n",
      "5 \n",
      "\n",
      "<class 'llama_index.schema.Document'>\n",
      "Doc ID: 6ceddbe9-3a2f-49ef-97d8-2eb8c385ba48\n",
      "Text: Real-Time Detection of DNS Exﬁltration and Tunneling from\n",
      "Enterprise Networks Jawad Ahmed∗,†, Hassan Habibi Gharakheili∗, Qasim\n",
      "Raza∗, Craig Russell†, and Vijay Sivaraman∗ ∗Electrical Engineering\n",
      "and Telecommunications, University of New South Wales, Sydney,\n",
      "Australia. †CSIRO Data61, Sydney, Australia. Emails: {j.ahmed,\n",
      "h.habibi }@unsw.edu.au, q...\n"
     ]
    }
   ],
   "source": [
    "print(type(documents), \"\\n\")\n",
    "print(len(documents), \"\\n\")\n",
    "print(type(documents[0]))\n",
    "print(documents[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import Document\n",
    "document = Document(text = \"\\n\\n\".join([doc.text for doc in documents]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import VectorStoreIndex\n",
    "from llama_index import ServiceContext\n",
    "from llama_index.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo\", temperature=0.1)\n",
    "service_context = ServiceContext.from_defaults(llm=llm, embed_model=\"local:BAAI/bge-small-en-v1.5\")\n",
    "\n",
    "index = VectorStoreIndex.from_documents([document], service_context=service_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"what are the final parameters that were used in the final model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The final parameters used in the final model are as follows: \n",
      "- Number of trees: 2\n",
      "- Height limit of trees: 18\n",
      "- Contamination rate: 2%\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_questions = []\n",
    "with open ('eval_questions.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        item = line.strip()\n",
    "        print(item)\n",
    "        eval_questions.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_question = \"what were the final parameters that were used in the model \"\n",
    "eval_questions.append(new_question)\n",
    "eval_questions.append(\"what were the final attributes that were used\")\n",
    "eval_questions.append(\"what were all the evaluation metrics used\")\n",
    "eval_questions.append(\"what were all the references that was used\")\n",
    "eval_questions.append(\"what were all the algorithms that were tested out\")\n",
    "eval_questions.append(\"what was the final goal of the author and did they achieve it \")\n",
    "eval_questions.append(\"what does each attribute mean in the aritcle\")\n",
    "eval_questions.append(\"what is is that this paper is trying to accomplish\")\n",
    "eval_questions.append(\"How was the data set collected\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"eval_questions.txt\", \"w\") as file:\n",
    "    for item in eval_questions:\n",
    "        file.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['what were the final parameters that were used in the model ', 'what were the final attributes that were used', 'what were all the evaluation metrics used', 'what were all the references that was used', 'what were all the algorithms that were tested out', 'what was the final goal of the author and did they achieve it ', 'what does each attribute mean in the aritcle', 'what is is that this paper is trying to accomplish', 'How was the data set collected']\n"
     ]
    }
   ],
   "source": [
    "print(eval_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KEY SET: OPENAI_API_KEY\n"
     ]
    }
   ],
   "source": [
    "from trulens_eval import Tru\n",
    "tru = Tru()\n",
    "\n",
    "tru.reset_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo\", temperature=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'build_sentence_window_index' from 'utils' (/Users/abhinay/Library/Python/3.9/lib/python/site-packages/utils/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m/Users/abhinay/Documents/GitHub/AI_Implements_AI/Deeplearning_ADV_RAG.ipynb Cell 14\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/abhinay/Documents/GitHub/AI_Implements_AI/Deeplearning_ADV_RAG.ipynb#X16sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m build_sentence_window_index\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/abhinay/Documents/GitHub/AI_Implements_AI/Deeplearning_ADV_RAG.ipynb#X16sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m sentence_index \u001b[39m=\u001b[39m build_sentence_window_index(document, llm, embed_model \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mlocal:BAAI/bge-small-en-v1.5\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/abhinay/Documents/GitHub/AI_Implements_AI/Deeplearning_ADV_RAG.ipynb#X16sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m                                              save_dir\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msentence_index\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'build_sentence_window_index' from 'utils' (/Users/abhinay/Library/Python/3.9/lib/python/site-packages/utils/__init__.py)"
     ]
    }
   ],
   "source": [
    "from utils import build_sentence_window_index\n",
    "\n",
    "sentence_index = build_sentence_window_index(document, llm, embed_model = \"local:BAAI/bge-small-en-v1.5\",\n",
    "                                             save_dir=\"sentence_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
