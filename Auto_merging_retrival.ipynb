{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_openai_api_key\n",
    "\n",
    "get_openai_api_key()\n",
    "import os\n",
    "import openai\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import SimpleDirectoryReader\n",
    "\n",
    "documents = SimpleDirectoryReader(\n",
    "    input_files= [\"/Users/abhinay/Desktop/Real-Time_Detection_of_DNS_Exfiltration_and_Tunneling_from_Enterprise_Networks-1.pdf\"]\n",
    ").load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import Document\n",
    "\n",
    "document = Document(text = \"/n/n\".join([doc.text for doc in documents]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.node_parser import HierarchicalNodeParser\n",
    "\n",
    "node_parser = HierarchicalNodeParser.from_defaults(chunk_sizes=[2048, 512, 128])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = node_parser.get_nodes_from_documents([document])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We note that some malicious\n",
      "domains may appear among top KAlexa domains due to\n",
      "a burst of requests from a high number of infected clients\n",
      "querying them. For the benign training instances, we only\n",
      "use top 10,000 primary domains. We also include FQDNs\n",
      "for “ sophosxl.net ” domain (related to a benign anti-virus\n",
      "application) which is not among the top 10K Majestic dataset.\n"
     ]
    }
   ],
   "source": [
    "from llama_index.node_parser import get_leaf_nodes\n",
    "\n",
    "leaf_nodes = get_leaf_nodes(nodes)\n",
    "\n",
    "print(leaf_nodes[30].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_by_id = {node.node_id: node for node in nodes}\n",
    "\n",
    "parent_node = nodes_by_id[leaf_nodes[30].parent_node.node_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We note that some malicious\n",
      "domains may appear among top KAlexa domains due to\n",
      "a burst of requests from a high number of infected clients\n",
      "querying them. For the benign training instances, we only\n",
      "use top 10,000 primary domains. We also include FQDNs\n",
      "for “ sophosxl.net ” domain (related to a benign anti-virus\n",
      "application) which is not among the top 10K Majestic dataset.\n",
      "C. Algorithms and Tuning Parameters\n",
      "The objective is to maximize detection of anomalous queries\n",
      "while reducing the rate of false alarms ( i.e.,incorrectly detect-\n",
      "ing a normal query as anomalous, or vice versa). Many of su-\n",
      "pervised machine-learning algorithms for detecting anomalies\n",
      "such as one-class SVM and Replicator Neural Network suffer\n",
      "from high false alarms since they are optimized for proﬁling\n",
      "the inlier behavior rather than detecting anomalies. We employ\n",
      "“Isolation Forest ( iForest )” [23] which is an effective algorithm\n",
      "in detecting anomalous instances in high-dimensional datasets\n",
      "with minimal memory and time complexities.\n",
      "The iForest algorithm “isolates” observations by randomly\n",
      "selecting an attribute and then randomly selecting a split value\n",
      "in the range of values ( i.e.,between min and max) for the se-\n",
      "lected attribute. Since recursive partitioning can be represented\n",
      "by a tree structure, the number of splittings required to isolate\n",
      "an instance is equivalent to the path length from the root node\n",
      "to the terminating node. This path length, averaged over a\n",
      "forest of such random trees, is a measure of normality and the\n",
      "decision function ( i.e.,normal instances are expected to have\n",
      "a fairly large path length in random partitioning). Therefore,\n",
      "when a forest of random trees collectively produces shorter\n",
      "path lengths for a particular instance, it is highly likely to be\n",
      "an anomaly.\n",
      "Algorithm Tuning: We used scikit-learn and its APIs,\n",
      "an open-source machine-learning package written in Python,\n",
      "to train and test our machine. We have used three tuning\n",
      "parameters for iForest during training phase namely number\n",
      "of trees ( nestimators ), height limit of trees ( max samples ),\n",
      "and contamination rate. We tune the value of each parameter\n",
      "while ﬁxing the other two parameters and validate the accuracy\n",
      "of our machine for both benign and malicious instances (that\n",
      "we have the ground truth) in both organizations.\n"
     ]
    }
   ],
   "source": [
    "print(parent_node.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(model = \"gpt-3.5-turbo\", temperature=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import ServiceContext\n",
    "\n",
    "auto_merging_context = ServiceContext.from_defaults(\n",
    "    llm=llm, \n",
    "    embed_model=\"local:BAAI/bge-small-en-v1.5\",\n",
    "    node_parser=node_parser,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import StorageContext, VectorStoreIndex\n",
    "\n",
    "storage_context = StorageContext.from_defaults()\n",
    "storage_context.docstore.add_documents(nodes)\n",
    "\n",
    "automerging_index = VectorStoreIndex(leaf_nodes, storage_context=storage_context,\n",
    "                                     service_context=auto_merging_context)\n",
    "\n",
    "automerging_index.storage_context.persist(persist_dir=\"./merging_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.indices.postprocessor import SentenceTransformerRerank\n",
    "from llama_index.retrievers import AutoMergingRetriever\n",
    "from llama_index.query_engine import RetrieverQueryEngine\n",
    "from sympy import true\n",
    "\n",
    "automerging_retriever = automerging_index.as_retriever(similarity_top_k = 12)\n",
    "\n",
    "retriever = AutoMergingRetriever(automerging_retriever,\n",
    "                                 automerging_index.storage_context,\n",
    "                                 verbose=true)\n",
    "\n",
    "rerank = SentenceTransformerRerank(top_n=6, \n",
    "                                   model=\"BAAI/bge-reranker-base\")\n",
    "\n",
    "auto_merging_engine = RetrieverQueryEngine.from_args(automerging_retriever,\n",
    "                                                     node_postprocessors=[rerank])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
